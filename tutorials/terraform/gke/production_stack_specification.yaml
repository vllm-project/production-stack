servingEngineSpec:
  strategy:
    type: Recreate
  runtimeClassName: ""
  nodeSelector:
    app: vllm-inference
    nvidia.com/gpu: present
  tolerations:
  - key: nvidia.com/gpu
    operator: Equal
    value: present
    effect: NoSchedule
  modelSpec:
  - name: "opt125m"
    repository: "vllm/vllm-openai"
    tag: "latest"
    modelURL: "facebook/opt-125m"

    replicaCount: 1

    requestCPU: 1
    requestMemory: "8Gi"
    requestGPU: 1

    pvcStorage: "10Gi"
    pvcAccessMode:
      - ReadWriteOnce

routerSpec:
  nodeSelector:
    app: mgmt-node
  resources:
    requests:
      cpu: 1
      memory: 4G
    limits:
      cpu: 2
      memory: 8G
