servingEngineSpec:
  runtimeClassName: ""
  modelSpec:
  - name: "gpt-oss-20b"
    repository: "lmcache/vllm-openai"
    tag: "v0.3.9post2"
    modelURL: "openai/gpt-oss-20b"
    replicaCount: 2
    requestCPU: 8
    requestMemory: "128Gi"
    requestGPU: 1
    pvcStorage: "256Gi"
    vllmConfig:
      enablePrefixCaching: true
      maxModelLen: 8000
      gpuMemoryUtilization: "0.9"

    lmcacheConfig:
      enabled: true
      cpuOffloadingBufferSize: "60"
      enableController: true

      controllerPort: 9000
      workerPorts: "8001"
      p2pHost: "localhost"
      p2pInitPorts: "30081"
      workerHeartbeatTime: "30"

    env:
      - name: LMCACHE_LOG_LEVEL
        value: "DEBUG"
      - name: VLLM_LOGGING_LEVEL
        value: "DEBUG"
      - name: HF_HOME
        value: "/data"

routerSpec:
  repository: "lmcache/lmstack-router"
  tag: "latest"
  resources:
    requests:
      cpu: "1"
      memory: "2G"
    limits:
      cpu: "1"
      memory: "2G"
  routingLogic: "kvaware"
  lmcacheControllerPort: 9000
  sessionKey: "x-user-id"
