apiVersion: production-stack.vllm.ai/v1alpha1
kind: VLLMRouter
metadata:
  labels:
    app.kubernetes.io/name: production-stack
    app.kubernetes.io/managed-by: kustomize
  name: vllmrouter-sample
spec:
  enableRouter: true
  replicas: 1
  serviceDiscovery: k8s
  k8sLabelSelector: "app=vllmruntime-pd-sample"
  routingLogic: disaggregated_prefill
  engineScrapeInterval: 30
  requestStatsWindow: 60
  port: 80
  serviceAccountName: vllmrouter-sa

  # Image configuration
  image:
    registry: docker.io
    name: lmcache/vllm-router:debug-detailed
    pullPolicy: Never

  # Resource requirements
  resources:
    cpu: "2"
    memory: "8Gi"

  # Extra arguments for router
  extraArgs:
    - "--prefill-model-labels"
    - "Llama-3.2-1B-Instruct-prefill"
    - "--decode-model-labels"
    - "Llama-3.2-1B-Instruct-decode"
    - "--nixl-proxy-host"
    - "0.0.0.0"
    - "--nixl-proxy-port"
    - "7500"
    - "--nixl-peer-host"
    - "0.0.0.0"
    - "--nixl-peer-init-port"
    - "7300"
    - "--nixl-peer-alloc-port"
    - "7400"

  # Environment variables
  env:
    - name: LOG_LEVEL
      value: "info"
    - name: METRICS_ENABLED
      value: "true"
    - name: ENABLE_PD_DISAGGREGATION
      value: "true"
    - name: PD_PREFILL_SELECTOR
      value: "node-type=prefill"
    - name: PD_DECODE_SELECTOR
      value: "node-type=decode"

  # Node selector for pod scheduling
  nodeSelectorTerms:
    - matchExpressions:
        - key: kubernetes.io/os
          operator: In
          values:
            - linux
